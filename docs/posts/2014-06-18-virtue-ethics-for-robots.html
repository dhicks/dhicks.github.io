<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dan Hicks">
<meta name="dcterms.date" content="2014-06-18">

<title>Virtue Ethics for Robots – Dan Hicks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-cf3f2c26eef976f46b51aa29f3e196e4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/academicons-1.9.2/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/academicons-1.9.2/size.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Virtue Ethics for Robots – Dan Hicks">
<meta property="og:description" content="Website description">
<meta property="og:site_name" content="Dan Hicks ">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Dan Hicks</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../phrail.html"> 
<span class="menu-text">PHRAIL</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teaching</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="https://fairy-shrimp.netlify.app/">
 <span class="dropdown-text">Science, Technology, and Ethics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://fairy-shrimp-cr.netlify.app/">
 <span class="dropdown-text">Notes for Critical Reasoning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://data-science-methods.github.io/">
 <span class="dropdown-text">Methods of Data Science</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://orcid.org/0000-0001-7945-4416"> 
<span class="menu-text"><i class="fa-brands fa-orcid" aria-label="orcid"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=XvkwYZsAAAAJ&amp;hl=en"> 
<span class="menu-text"><i class="ai  ai-google-scholar" title="" style="color:"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://dhicks.github.io/cv"> 
<span class="menu-text"><i class="ai  ai-cv" title="" style="color:"></i></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dhicks/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:dhicks4@ucmerced.edu"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Virtue Ethics for Robots</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">automated</div>
                <div class="quarto-category">creativity</div>
                <div class="quarto-category">data</div>
                <div class="quarto-category">rights</div>
                <div class="quarto-category">robot</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Dan Hicks </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 18, 2014</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Autonomous automated systems — machines capable of acting on their own for extended periods of time in complex environments — have been a major trope of science fiction for as long as the genre has existed. Over the last ten years or so, autonomous systems research has advanced dramatically, and it is generally recognized that autonomous automated systems will be common in warfare and everyday life (at least in wealthy countries) within the next ten years or so.</p>
<p>In light of these developments, “robot ethics” has developed as a serious scholarly (and popular) topic. Dipping into this literature, I get the impression that much of robot ethics takes what I’m going to call a <em>principle-based approach</em> to ethics. On such an approach, ethical judgment is a matter of, first, identifying the correct set of ethical principles, and second, correctly applying those principles in a given situation. (I have some thoughts on why robot ethics has taken the principle-based approach, but I’ll leave them out here. I’d be happy to elaborate in the comments.)</p>
<p>In this post, I’m going to argue that a principle-based approach tends to overlook two important features of ethical judgments in complex situations. In addition, I think that these two features correspond to certain worries that many members of the public have about automated ethical decisionmaking — that is, about turning over responsibility for ethical decisions to autonomous automated systems. So, insofar as robot ethics want to (try to) assuage public concerns about autonomous automated systems, they should at least broaden their range of ethical approaches.</p>
<p>Before going further, I should make it clear that I’m not actually very familiar with the current state of robot ethics. I’ve glanced at a few things, and read some things shared (and in a couple of cases, written) by my advisor, Don Howard, over social media, and I’ve had a few discussions with my friend and co-author Charles Pence. But I am, professionally speaking, a philosopher with expertise in ethics, and I generally work within an approach to ethics that is sharply critical of the limitations of a principle-based approach. So hopefully my arguments here will be valuable to robot ethicists even if they are built on a hasty generalization.</p>
<p>My argument is going to contrast principle-based approaches to ethics with an alternative approach called <em>virtue ethics</em>. Within philosophical work on ethics, principle-based approaches — especially Kantian deontology, utilitarianism, and appeals to human rights — have been dominant for the last several centuries. Virtue ethics has been recognized as a distinct approach for about 40 or 50 years, but virtue ethicists trace their approach back to such ancient philosophers as Aristotle and Confucius, as well as traditional ethe (ethos, plural) of agrarian and nomadic hunting societies in Africa and the Americas.</p>
<p>The principle-based approaches generally focus on decisions about particular actions, and aim to find the one right or best course of action to take in a given situation. By contrast, virtue ethics generally focuses on the character of agents over time. Since they’re less concerned about what to do in particular situations, virtue ethicists tend to be more attentive to complexity and uncertainty in decisionmaking than principle-based approaches. In addition, virtue ethicists tend to be concerned about more aspects of our ethical lives than just making decisions. Consequently, virtue ethicists have developed the conceptual tools that I’ll use below, and it’s hard to find room for these tools in the principle-based approaches. Thus, again, robot ethicists should expand their approaches, so that they can make use of these virtue ethics tools.</p>
<p>To make my discussion concrete, let’s consider two cases, both of which seem to be common in robot ethics.</p>
<blockquote class="blockquote">
<p>An autonomous, automated soldier/weapons system is sent on a mission to engage with an enemy squad. The squad has barricaded themselves in a small building with a dozen children. Should the system engage the enemy — risking the lives of the children — or maintain its distance — risking the possibility that the enemy squad will escape?</p>
<p>An autonomous, automated car is transporting one passenger along a narrow street with parked cars on either side. A child suddenly runs out into the street from between two parked cars. The car does not have time to brake safely. Should it veer into the cars on the side of the street — risking the life of its passenger — or hit the child — risking its life?</p>
</blockquote>
<p>On the principle-based approach, the task for robot ethics is to identify the correct ethical principles to be applied in these cases, and so to determine the ethically correct course of action for the automated system.</p>
<p>However, I argue that <strong>there is no ethically correct course of action in either of these cases</strong>. Both cases are examples of <em>moral dilemmas</em>: situations in which every available course of action is, in some respect or another, seriously bad, wrong, or vicious. In the automated car case, both of the available options risk serious harm to moral innocents (people who do not deserve to be harmed). In the automated weapons system case, the choice is between serious harm to moral innocents now or serious harm later (after the enemy squad escapes).</p>
<p>Principle-based approaches have trouble recognizing moral dilemmas to the extent that they are based on a single fundamental ethical principle, such as Kant’s categorical imperative or utilitarianism’s principle of greatest happiness. On pain of contradiction, the fundamental ethical principle cannot imply both <em>the system should do X</em> and <em>the system should not do X</em>. Pluralist principle-based approaches — like Beauchamp and Childress’ principlism for biomedical ethics — do better here. But the impression I have is that writers in robot ethics generally do not recognize the moral dilemmas is these cases; instead, they keep searching for (and arguing about) “the” right answer.</p>
<p>Bernard Williams, Rosalind Hursthouse, and Lisa Tessman — three major virtue ethicists — all emphasize <em>regret</em> as an appropriate response to finding oneself in a moral dilemma. Consider an ordinary human being, rather than an autonomous system, in either of our example cases. We expect that this person, whatever they do, will feel ethically responsible for bringing about a serious harm; they will feel regret. The fact that they have done the best that they could do in terrible, regretful circumstances could mean that we will not punish them for, say, the death of the children. But they will still feel responsible. Furthermore, <strong>this feeling of regret is an ethically appropriate response to a moral dilemma</strong>. Someone who does not feel bad in any way at all about the death of the children is callous, morally reprehensible, and <a href="http://behavenet.com/node/21650">a candidate for antisocial personality disorder according to the DSM IV criteria</a>.</p>
<p>This brings us to the first concern that, I think, many people have about autonomous ethical decisionmaking. In the popular imagination, robots are cold, calculating, and callous; they simply “follow their programming” wherever it leads them. In other words, <strong>autonomous systems do not experience regret when confronted with moral dilemmas, and so respond to these situations in disturbing and ethically inappropriate ways</strong>. In this respect, concerns about automated ethical decisionmaking parallel Cold War-era concerns about scientific-military technocrats — Dr Strangelove and HAL are both morally reprehensible and disturbing characters because of their callous, calculating decisionmaking processes.</p>
<p>I presented our two example cases dichotomously: the autonomous automated system must choose exactly one of two options, A or B. But of course real-world cases aren’t that simple; there are many different courses of action that could be taken, and many different options within each possible course. In the case of the automated soldier/weapons system, the system could rush into the building, relying on its superhuman reaction times to take out the enemy before any of the children are hurt; it could use smoke or some other means to drive everyone out of the building; or it could call in automated or human support.</p>
<p>Principle-based approaches generally assume that the range of possible course of action is fixed and known in advance. The principles are used to evaluate each possible course, and the correct course of action is the one that comes out highest on this evaluation. Even Beauchamp and Childress’ approach seems to assume that this is how ethical decisionmaking works. But the observation in the last paragraph indicates that, in general, we don’t know the range of possible courses of action in advance.</p>
<p>Indeed, <strong>in ethically complex and challenging situations, there is a crucial role for creativity and innovation</strong>. Sometimes we can appear to be in a moral dilemma because of serious problems with all of the simple, obvious options. But, by taking advantage of particular features of the situation in creative ways, we can find a way to avoid the dilemma. Because principle-based approaches generally assume that all of the possible courses of action are known in advance, they generally miss this role for creativity.</p>
<p>I want to stress that this role for creativity is closely tied to the particular features of the situation. We might call this <em>tactical creativity</em>, to distinguish it from the <em>strategic creativity</em> that can develop novel approaches to general situations. Both strategic and tactical creativity are invaluable resources for resolving ethical dilemmas and novel situations; but tactical creativity, unlike strategic creativity, can only be exercised “on the ground,” in the particular situation at hand. Consequently, <strong>correctly resolving some apparent moral dilemmas requires tactical creativity</strong>.</p>
<p>This brings us to the second concern about automated ethical decisionmaking. Robots, in the popular imagination, are uncreative and unadaptable; as with the first concern, they simply “follow their programming,” rigidly and without deviation. In other words, while their designers might exercise strategic creativity, autonomous automated systems are incapable of tactical creativity. But, as I argued above, tactical creativity is required to resolve some apparent moral dilemmas. Thus, <strong>autonomous automated systems are more likely than humans to incorrectly resolve some apparent moral dilemmas</strong>. Because these systems are rigid and uncreative, they are incapable of seeing the creative way out of the dilemma. And so they are more likely than creative humans to do unnecessary ethical damage.</p>
<p>In this post, I’ve raised two concerns for robot ethicists, drawing on work in virtue ethics. First, because autonomous systems do not experience regret, they do not respond appropriately to finding themselves in moral dilemmas. And second, because these systems lack creativity, they are incapable of correctly resolving some moral dilemmas.</p>
<p>My arguments for these concerns draw on the popular image of robots and other autonomous automated systems as cold, callous, and calculating. Some readers might think that these concerns can be responded to by changing the popular image of robots — by encouraging people to think of Data from <em>Star Trek</em> or the robot in <em>Robot and Frank</em>, rather than HAL. But this would be superficial. What’s necessary, I think, is to think of ethical deliberation by autonomous automated systems not in terms of applying a set of principles, but instead as having and exercising a set of responsive capacities, including regret and creativity. This might require a radical change in the way roboticists approach system design, but (if successful) it would produce robots with <em>genuinely virtuous character</em>.</p>
<div id="footer">
<p><span id="timestamp">June 18th, 2014 11:46am</span> <span class="tag">robot ethics</span> <span class="tag">virtue ethics</span> <span class="tag">philosophy of technology</span></p>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-copyright"><h2 class="anchored quarto-appendix-heading">Copyright</h2><div class="quarto-appendix-contents"><div>Dan Hicks</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/dhicks\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>